{
 "metadata": {
  "name": "",
  "signature": "sha256:4596cee47f08c5677bb52948e1d54954d9359316440e3ac008827bfb47d4ae36"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Naive Bayes Classification\n",
      "\n",
      "Concepts in this Notebook:\n",
      "- Naive Bayes Classifiers\n",
      "- Train Test Split\n",
      "- Vectorizer (fit and transform)\n",
      "- Accuracy of training and test data\n",
      "- Sparse array vs normal array\n",
      "- Comparing classifiers in sklearn\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some extra resources:\n",
      "\n",
      "- [SKL Naive Bayes Documentation](http://scikit-learn.org/stable/modules/naive_bayes.html)\n",
      "\n",
      "- [Stanford Naive Bayes Math](http://nlp.stanford.edu/IR-book/pdf/13bayes.pdf)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.cross_validation import train_test_split\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "critics = pd.read_csv('/home/vagrant/notebooks/fall_2014_lessons/datasets/rt_critics.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "critics.quote[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "'A winning animated feature that has something for everyone on the age spectrum.'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "critics.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>        Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>    Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>  TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>        David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>      Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Jonathan Rosenbaum</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Chicago Reader</td>\n",
        "      <td> An entertaining computer-generated, hyperreali...</td>\n",
        "      <td> 2008-03-10</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "               critic  fresh    imdb     publication                                              quote review_date  rtid      title\n",
        "0         Derek Adams  fresh  114709        Time Out  So ingenious in concept, design and execution ...  2009-10-04  9559  Toy story\n",
        "1     Richard Corliss  fresh  114709   TIME Magazine                  The year's most inventive comedy.  2008-08-31  9559  Toy story\n",
        "2         David Ansen  fresh  114709        Newsweek  A winning animated feature that has something ...  2008-08-18  9559  Toy story\n",
        "3       Leonard Klady  fresh  114709         Variety  The film sports a provocative and appealing st...  2008-06-09  9559  Toy story\n",
        "4  Jonathan Rosenbaum  fresh  114709  Chicago Reader  An entertaining computer-generated, hyperreali...  2008-03-10  9559  Toy story"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Multinomial vs Bernoulli Models\n",
      "\n",
      "- The **Multinomial model** actually counts occurences out of all possible occurences for probability - better for greater features\n",
      "- The **Bernoulli model** counts only all documents with presence of the word - better for fewer features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.naive_bayes import BernoulliNB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### How the Count Vectorizer Works"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\n",
      "### How the Count Vectorizer Works\n",
      "#\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "text = ['Math is great', 'Math is really great', 'Exciting exciting Math']\n",
      "print \"Original text:\\n\\t\", '\\n\\t'.join(text)\n",
      "\n",
      "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
      "\n",
      "# call `fit` to build the vocabulary\n",
      "vectorizer.fit(text)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Original text:\n",
        "\tMath is great\n",
        "\tMath is really great\n",
        "\tExciting exciting Math\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2499: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
        "  VisibleDeprecationWarning)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "CountVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
        "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "        tokenizer=None, vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Q: What is an ngram?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### A: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# display the names of the features\n",
      "vectorizer.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[u'exciting',\n",
        " u'exciting exciting',\n",
        " u'exciting math',\n",
        " u'great',\n",
        " u'is',\n",
        " u'is great',\n",
        " u'is really',\n",
        " u'math',\n",
        " u'math is',\n",
        " u'really',\n",
        " u'really great']"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# call `transform` to convert text to a bag of words\n",
      "x = vectorizer.transform(text)\n",
      "print x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 3)\t1\n",
        "  (0, 4)\t1\n",
        "  (0, 5)\t1\n",
        "  (0, 7)\t1\n",
        "  (0, 8)\t1\n",
        "  (1, 3)\t1\n",
        "  (1, 4)\t1\n",
        "  (1, 6)\t1\n",
        "  (1, 7)\t1\n",
        "  (1, 8)\t1\n",
        "  (1, 9)\t1\n",
        "  (1, 10)\t1\n",
        "  (2, 0)\t2\n",
        "  (2, 1)\t1\n",
        "  (2, 2)\t1\n",
        "  (2, 7)\t1\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CountVectorizer uses a sparse array to save memory, but it's easier in this assignment to \n",
      "# convert back to a \"normal\" numpy array\n",
      "x_back = x.toarray()\n",
      "x_back"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "array([[0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0],\n",
        "       [0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1],\n",
        "       [2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0]])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Transformed text vector is \\n\", x\n",
      "\n",
      "# `get_feature_names` tracks which word is associated with each column of the transformed x\n",
      "print\n",
      "print \"Words for each feature:\"\n",
      "print vectorizer.get_feature_names()\n",
      "\n",
      "# Notice that the bag of words treatment doesn't preserve information about the *order* of words, \n",
      "# just their frequency"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Transformed text vector is \n",
        "  (0, 3)\t1\n",
        "  (0, 4)\t1\n",
        "  (0, 5)\t1\n",
        "  (0, 7)\t1\n",
        "  (0, 8)\t1\n",
        "  (1, 3)\t1\n",
        "  (1, 4)\t1\n",
        "  (1, 6)\t1\n",
        "  (1, 7)\t1\n",
        "  (1, 8)\t1\n",
        "  (1, 9)\t1\n",
        "  (1, 10)\t1\n",
        "  (2, 0)\t2\n",
        "  (2, 1)\t1\n",
        "  (2, 2)\t1\n",
        "  (2, 7)\t1\n",
        "\n",
        "Words for each feature:\n",
        "[u'exciting', u'exciting exciting', u'exciting math', u'great', u'is', u'is great', u'is really', u'math', u'math is', u'really', u'really great']\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Preparing our Features (X) and Target (Y) for Training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "X is a (nreview, nwords) array. Each row corresponds to a bag-of-words representation for a single review. This will be the input to the model.\n",
      "\n",
      "Y is a nreview-element 1/0 array, encoding whether a review is Fresh (1) or Rotten (0). This is the desired output"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a vector where each row is bag-of-words for a single quote\n",
      "X = vectorizer.fit_transform(critics.quote) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# temporary variable\n",
      "rotten_vectorizer = vectorizer.fit(critics.quote)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create an array where each element encodes whether the array is Fresh or Rotten\n",
      "Y = (critics.fresh == 'fresh').values.astype(np.int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use SKLearn's train_test_split \n",
      "from sklearn.cross_validation import train_test_split\n",
      "xtrain, xtest, ytrain, ytest = train_test_split(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Creating the Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a few helper functions\n",
      "def accuracy_report(_clf):\n",
      "    print \"Accuracy: %0.2f%%\" % (100 * _clf.score(xtest, ytest))\n",
      "\n",
      "    #Print the accuracy on the test and training dataset\n",
      "    training_accuracy = _clf.score(xtrain, ytrain)\n",
      "    test_accuracy = _clf.score(xtest, ytest)\n",
      "\n",
      "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
      "    \n",
      "# a function to run some tests\n",
      "def AnalyzeReview(testquote):\n",
      "    print \"\\\"\"  + testquote + \"\\\" is judged by clasifier to be...\"\n",
      "    testquote = rotten_vectorizer.transform([testquote])\n",
      "\n",
      "    if (clf.predict(testquote)[0] == 1):\n",
      "        print \"... a fresh review.\"\n",
      "    else:\n",
      "        print \"... a rotten review.\"\n",
      "    return(clf.predict(testquote)[0])\n",
      "accuracy_report(clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 77.06%\n",
        "Accuracy on training data: 1.00\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "print \"MultinomialNB:\"\n",
      "clf = MultinomialNB().fit(xtrain, ytrain)\n",
      "accuracy_report(clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MultinomialNB:\n",
        "Accuracy: 77.26%\n",
        "Accuracy on training data: 0.99\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import BernoulliNB\n",
      "print \"BernoulliNB:\"\n",
      "clf = BernoulliNB().fit(xtrain, ytrain)\n",
      "accuracy_report(clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BernoulliNB:\n",
        "Accuracy: 65.09%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.86"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "print \"Logistic Regression:\"\n",
      "clf = LogisticRegression().fit(xtrain, ytrain)\n",
      "accuracy_report(clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Logistic Regression:\n",
        "Accuracy: 77.06%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 1.00\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeReview(\"film\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"film\" is judged by clasifier to be...\n",
        "... a fresh review.\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "1"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Save prediction and probability\n",
      "\n",
      "# Outputs of X (just first column)\n",
      "prob = clf.predict_proba(X)[:, 0]\n",
      "\n",
      "predict = clf.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y==0 #(provides a mask where the actual review is bad)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "array([False, False, False, ..., False, False, False], dtype=bool)"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# argsort returns the positions of the top n sorted values\n",
      "np.argsort((prob[Y==0]))[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "array([3575, 2369, 2315, 4828, 4981])"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Review errors\n",
      "bad_rotten = np.argsort(prob[Y == 0])[:5]\n",
      "bad_fresh = np.argsort(prob[Y == 1])[-5:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Mis-predicted Rotten quotes\"\n",
      "print '---------------------------'\n",
      "for row in bad_rotten:\n",
      "    print critics[Y == 0].quote.irow(row)\n",
      "    print\n",
      "\n",
      "print \"Mis-predicted Fresh quotes\"\n",
      "print '--------------------------'\n",
      "for row in bad_fresh:\n",
      "    print critics[Y == 1].quote.irow(row)\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mis-predicted Rotten quotes\n",
        "---------------------------\n",
        "The Waterboy is arguably Sandler's most enjoyable motion picture to date, but it's still far from a masterpiece.\n",
        "\n",
        "Nava, who started his feature-film career with El Norte, is a good director who invariably finds a strong rapport with his actors. He's not much of a writer, though, and he should think twice about creating dialogue for his future projects.\n",
        "\n",
        "Take away the ethnic/pregnancy angles, and we've seen this premise countless times -- all the way back to the spate of post-World War II romances about returning veterans and the mates they married in a blink.\n",
        "\n",
        "A lightweight romance for the senior crowd, Last Chance Harvey does nothing in particular, but it does it fairly well thanks to stars Dustin Hoffman and Emma Thompson.\n",
        "\n",
        "If most of the budget has gone to ordnance and blood squibs, director Lexi Alexander films the sprays of gore with an artisan's eye, and the results make effective if morally indefensible movie red meat.\n",
        "\n",
        "Mis-predicted Fresh quotes\n",
        "--------------------------\n",
        "This holiday contender from John Hughes is too crass, too loud and too violent to be added blithely to Christmas viewing traditions. But it is funny.\n",
        "\n",
        "Might it be a serious attempt to right some unretrievable wrong via gallows humor which avoids the polemics? This seems to be the course taken; the attempt at least can be respected in theory.\n",
        "\n",
        "It sounds like the stuff of soap operas or bad porn, but Kureishi's script is too intelligent and empathetic to titillate.\n",
        "\n",
        "The movie's basic joke holds that the overbearing, unselfconscious Americans will do anything and say anything (and usually as loudly as possible), while the timorous British are nearly too polite to breathe.\n",
        "\n",
        "There's too much talent and too strong a story to mess it up. There was potential for more here, but this incarnation is nothing to be ashamed of, and some of the actors answer the bell.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}