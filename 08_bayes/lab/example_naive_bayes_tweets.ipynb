{
 "metadata": {
  "name": "",
  "signature": "sha256:f1647c36878949c901ecb09b7829b8dc7fc33b039dcd551409e0ba62db4e3c3d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Tweet Sentiment Analysis\n",
      "\n",
      "Create a twitter classifier with naive bayes and check the sentiment for a keyword of your choice.\n",
      "Train your classifier with the \"tweet_training.csv\" file\n",
      "\n",
      "Sentiment is described as \"polarity,\" where:\n",
      "\n",
      "- \"0\" = negative\n",
      "- \"4\" = positive"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweets = pd.read_csv('https://raw.githubusercontent.com/vinharng/fall_2014_lessons/master/datasets/tweet_training.csv', delimiter=';', index_col='id')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweets.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>polarity</th>\n",
        "      <th>tweet</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>id</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1467933112</th>\n",
        "      <td> 0</td>\n",
        "      <td> the angel is going to miss the athlete this we...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2323395086</th>\n",
        "      <td> 0</td>\n",
        "      <td> It looks as though Shaq is getting traded to C...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1467968979</th>\n",
        "      <td> 0</td>\n",
        "      <td>    @clarianne APRIL 9TH ISN'T COMING SOON ENOUGH </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1990283756</th>\n",
        "      <td> 0</td>\n",
        "      <td> drinking a McDonalds coffee and not understand...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1988884918</th>\n",
        "      <td> 0</td>\n",
        "      <td> So dissapointed Taylor Swift doesnt have a Twi...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "            polarity                                              tweet\n",
        "id                                                                     \n",
        "1467933112         0  the angel is going to miss the athlete this we...\n",
        "2323395086         0  It looks as though Shaq is getting traded to C...\n",
        "1467968979         0     @clarianne APRIL 9TH ISN'T COMING SOON ENOUGH \n",
        "1990283756         0  drinking a McDonalds coffee and not understand...\n",
        "1988884918         0  So dissapointed Taylor Swift doesnt have a Twi..."
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = CountVectorizer(ngram_range=(1,5),stop_words='english')\n",
      "# need to set the output of this method to a variable\n",
      "# vector of all tweets\n",
      "tweets_vectorizer = vectorizer.fit(tweets.tweet)\n",
      "print tweets_vectorizer.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'binary': False, 'lowercase': True, 'stop_words': 'english', 'vocabulary': None, 'tokenizer': None, 'decode_error': u'strict', 'dtype': <type 'numpy.int64'>, 'charset_error': None, 'charset': None, 'analyzer': u'word', 'encoding': u'utf-8', 'ngram_range': (1, 5), 'max_df': 1.0, 'min_df': 1, 'max_features': None, 'input': u'content', 'strip_accents': None, 'token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b', 'preprocessor': None}\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# a few helper functions\n",
      "def accuracy_report(_clf):\n",
      "    print \"Accuracy: %0.2f%%\" % (100 * _clf.score(xtest, ytest))\n",
      "\n",
      "    #Print the accuracy on the test and training dataset\n",
      "    training_accuracy = _clf.score(xtrain, ytrain)\n",
      "    test_accuracy = _clf.score(xtest, ytest)\n",
      "\n",
      "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
      "    \n",
      "# a function to run some tests\n",
      "def analyze_review(testquote, vect, _clf):\n",
      "    print \"'%s' is judged by the clasifier to be...\" % (testquote)\n",
      "    testquote = vect.transform([testquote])\n",
      "    prob0 = _clf.predict_proba(testquote)[0][0]\n",
      "    prob1 = _clf.predict_proba(testquote)[0][1]\n",
      "    if (_clf.predict(testquote)[0] == 1):\n",
      "        print \"... a positive tweet with probability %02f.\" % prob1\n",
      "    else:\n",
      "        print \"... a negative tweet with probability %02f.\" % prob0\n",
      "    return(_clf.predict(testquote)[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_transform = vectorizer.transform(tweets.tweet)\n",
      "x_transform.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "(2034, 48070)"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_fit_transform = vectorizer.fit_transform(tweets.tweet)\n",
      "x_fit_transform.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "(2034, 48070)"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# don't need to do this step:\n",
      "#x_back = x.toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y = (tweets.polarity == 4).values.astype(np.int)\n",
      "Y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "(2034,)"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "xtrain, xtest, ytrain, ytest = train_test_split(x, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitmt= MultinomialNB().fit(xtrain, ytrain)\n",
      "print fitmt.score(xtrain,ytrain)\n",
      "print fitmt.score(xtest,ytest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.99737704918\n",
        "0.679764243615\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import BernoulliNB\n",
      "\n",
      "fitbm=BernoulliNB().fit(xtrain, ytrain)\n",
      "print fitbm.score(xtrain,ytrain)\n",
      "print fitbm.score(xtest,ytest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.771147540984\n",
        "0.705304518664\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "fitlg=LogisticRegression().fit(xtrain, ytrain)\n",
      "print fitlg.score(xtrain,ytrain)\n",
      "print fitlg.score(xtest,ytest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.998032786885\n",
        "0.819253438114\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweet1=\"@DataDAVE thanks for the awesome twitter dataset!!\"\n",
      "tweet2=\"I just don't understand lesso!??!\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#rename tweet1 to create a new variable\n",
      "tweet1_vec = tweets_vectorizer.transform([tweet1])\n",
      "\n",
      "fitlg.predict(tweet1_vec)[0]\n",
      "fitlg.predict_proba(tweet1_vec)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "array([ 0.24852974,  0.75147026])"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'fitlg:'\n",
      "analyze_review(tweet1, tweets_vectorizer, fitlg)\n",
      "analyze_review(tweet2, tweets_vectorizer, fitlg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fitlg:\n",
        "'@DataDAVE thanks for the awesome twitter dataset!!' is judged by the clasifier to be...\n",
        "... a positive tweet with probability 0.751470.\n",
        "'I just don't understand lesso!??!' is judged by the clasifier to be...\n",
        "... a negative tweet with probability 0.904575.\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 135,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'multinomial'\n",
      "analyze_review(tweet1, tweets_vectorizer, fitmt)\n",
      "analyze_review(tweet2, tweets_vectorizer, fitmt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "multinomial\n",
        "'@DataDAVE thanks for the awesome twitter dataset!!' is judged by the clasifier to be...\n",
        "... a positive tweet with probability 0.983670.\n",
        "'I just don't understand lesso!??!' is judged by the clasifier to be...\n",
        "... a negative tweet with probability 0.995360.\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 136,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'bernoulli'\n",
      "analyze_review(tweet1, tweets_vectorizer, fitbm)\n",
      "analyze_review(tweet2, tweets_vectorizer, fitbm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "bernoulli\n",
        "'@DataDAVE thanks for the awesome twitter dataset!!' is judged by the clasifier to be...\n",
        "... a negative tweet with probability 1.000000.\n",
        "'I just don't understand lesso!??!' is judged by the clasifier to be...\n",
        "... a negative tweet with probability 1.000000."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 137,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#See this error!:\n",
      "tweets_vectorizer.transform(tweet1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "<50x48070 sparse matrix of type '<type 'numpy.int64'>'\n",
        "\twith 0 stored elements in Compressed Sparse Row format>"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Copy of the traceback:\n",
      "\n",
      "```python\n",
      "ValueError                                Traceback (most recent call last)\n",
      "<ipython-input-37-daa8514dd2b1> in <module>()\n",
      "      1 tweet1=vectorizer.fit_transform([tweet1])\n",
      "      2 \n",
      "----> 3 fitlg.predict(tweet1)[0]\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.pyc in predict(self, X)\n",
      "    213             Predicted class label per sample.\n",
      "    214         \"\"\"\n",
      "--> 215         scores = self.decision_function(X)\n",
      "    216         if len(scores.shape) == 1:\n",
      "    217             indices = (scores > 0).astype(np.int)\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.pyc in decision_function(self, X)\n",
      "    194         if X.shape[1] != n_features:\n",
      "    195             raise ValueError(\"X has %d features per sample; expecting %d\"\n",
      "--> 196                              % (X.shape[1], n_features))\n",
      "    197 \n",
      "    198         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\n",
      "ValueError: X has 15 features per sample; expecting 48070\n",
      "```\n",
      "\n",
      "#### **What does this error tell us?** \n",
      "    `X has 15 features per sample; expecting 48070`\n",
      "\n",
      "- that the shape of the predictor matrix is off"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# X has 15 features per sample; expecting 48070\n",
      "print 'tweet1.shape', tweet1.shape\n",
      "print 'x.shape', x.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tweet1.shape (1, 15)\n",
        "x.shape (2034, 48070)\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitlg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import screen image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitlg.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "array([[ 0.209322  ,  0.0463484 ,  0.0463484 , ..., -0.02465411,\n",
        "        -0.02465411, -0.02465411]])"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitlg.decision_function"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "<bound method LogisticRegression.decision_function of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)>"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitlg.fit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "<bound method LogisticRegression.fit of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)>"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitlg.fit_intercept"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitlg.fit_transform\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "<bound method LogisticRegression.fit_transform of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)>"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitlg.C"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitlg.get_params"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "<bound method LogisticRegression.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)>"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitlg.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "{'C': 1.0,\n",
        " 'class_weight': None,\n",
        " 'dual': False,\n",
        " 'fit_intercept': True,\n",
        " 'intercept_scaling': 1,\n",
        " 'penalty': 'l2',\n",
        " 'random_state': None,\n",
        " 'tol': 0.0001}"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitlg.multi_class"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "'ovr'"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitlg.transform"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "<bound method LogisticRegression.transform of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)>"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitlg.verbose = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitlg.predict??"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitlg.predict([tweet1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "X has 1 features per sample; expecting 48070",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-59-6567cda17cbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfitlg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtweet1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \"\"\"\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 196\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
        "\u001b[1;31mValueError\u001b[0m: X has 1 features per sample; expecting 48070"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}